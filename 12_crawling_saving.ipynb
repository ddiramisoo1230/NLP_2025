{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ddiramisoo1230/NLP_2025/blob/main/12_crawling_saving.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'red'> üêπ üëÄ üêæ **Crawling or Text Mining or Scraping**"
      ],
      "metadata": {
        "id": "i02GpCyLr0YR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2EZsUyZMs9F",
        "outputId": "f030ba55-7f2c-4c79-b2a9-457905f9af1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def get_wikipedia_page(title):\n",
        "    URL = \"https://en.wikipedia.org/w/api.php\" #Application Programming InterfaceÏùò ÏïΩÏûê. Ï±óÏßÄÌîºÌã∞ÏôÄ Ïó∞Í≤∞ÎêòÏñ¥ ÏòàÏïΩÎèÑ Î∞îÎ°ú Í∞ÄÎä•ÌïòÍ≤å Ìï† Ïàò ÏûàÏùå!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "    PARAMS = {\n",
        "        \"action\": \"query\",\n",
        "        \"format\": \"json\",\n",
        "        \"prop\": \"extracts\",\n",
        "        \"titles\": title,\n",
        "        \"explaintext\": 1\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \"\n",
        "                      \"(KHTML, like Gecko) Chrome/123.0 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(URL, params=PARAMS, headers=headers)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(\"HTTP error:\", response.status_code)\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        data = response.json()\n",
        "    except:\n",
        "        print(\"JSON decode error\")\n",
        "        print(\"Raw response:\", response.text[:500])\n",
        "        return None\n",
        "\n",
        "    pages = data.get(\"query\", {}).get(\"pages\", {})\n",
        "    page = next(iter(pages.values()))\n",
        "    return page.get(\"extract\", \"\")"
      ],
      "metadata": {
        "id": "jjnTjtQJTa4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = get_wikipedia_page(\"KPop Demon Hunters\")\n",
        "print(text[:500])         #Ïù∏Îç±Ïä§ ÎÑòÎ≤Ñ 0Î∂ÄÌÑ∞ 499ÍπåÏßÄ(500ÎØ∏Îßå)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qoldme_2TCV9",
        "outputId": "c68b7d93-0994-4f3d-d072-f93a8c258bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KPop Demon Hunters is a 2025 American animated musical urban fantasy film directed by Maggie Kang and Chris Appelhans from a screenplay they co-wrote with Danya Jimenez and Hannah McMechan. Produced by Sony Pictures Animation for Netflix, the film stars the voices of Arden Cho, Ahn Hyo-seop, May Hong, Ji-young Yoo, Yunjin Kim, Daniel Dae Kim, Ken Jeong, and Lee Byung-hun. The film follows a K-pop girl group, Huntrix, who lead double lives as demon hunters; they face off against a rival boy band,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titles = [\n",
        "    \"K-pop\",\n",
        "    \"Korean Wave\",\n",
        "    \"KPop Demon Hunters\",\n",
        "    \"Hybe\",\n",
        "    \"BTS\",\n",
        "    \"2024 Nobel Prize in Literature\",\n",
        "    \"Han Kang\",\n",
        "    \"Bong Joon Ho\",\n",
        "    \"Pachinko\",\n",
        "    \"Minjung Son\"\n",
        "]\n",
        "\n",
        "corpus = {}\n",
        "\n",
        "for t in titles:\n",
        "    txt = get_wikipedia_page(t)\n",
        "    if txt:\n",
        "        corpus[t] = txt\n",
        "    else:\n",
        "        print(\"Failed:\", t)\n",
        "\n",
        "# Show first 200 chars for each\n",
        "for title, text in corpus.items():\n",
        "    print(\"\\n====\", title, \"====\")\n",
        "    print(text[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIvw_0cpjOz_",
        "outputId": "6d92557f-7062-4929-8b2d-6eaf3de1a099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed: Minjung Son\n",
            "\n",
            "==== K-pop ====\n",
            "K-pop (Korean: ÏºÄÏù¥Ìåù; RR: Keipap; an abbreviation of \"Korean popular music\") is a form of popular music originating in South Korea. The music genre that the term is used to refer to colloquially emerged\n",
            "\n",
            "==== Korean Wave ====\n",
            "The Korean Wave, or hallyu (Korean: ÌïúÎ•ò; ), refers to the rapid global rise in South Korean popular culture since the 1990s. It is led by the spread of K-pop, K-dramas, and films, with key successes in\n",
            "\n",
            "==== KPop Demon Hunters ====\n",
            "KPop Demon Hunters is a 2025 American animated musical urban fantasy film directed by Maggie Kang and Chris Appelhans from a screenplay they co-wrote with Danya Jimenez and Hannah McMechan. Produced b\n",
            "\n",
            "==== Hybe ====\n",
            "Hybe Co., Ltd. (Korean: ÌïòÏù¥Î∏å; haibeu), commonly known as simply Hybe, is a South Korean multinational entertainment company established in 2005 by Bang Si-hyuk as Big Hit Entertainment Co., Ltd.\n",
            "The co\n",
            "\n",
            "==== BTS ====\n",
            "BTS (Korean: Î∞©ÌÉÑÏÜåÎÖÑÎã®; RR: Bangtan Sonyeondan; lit. Bulletproof Boy Scouts), also known as the Bangtan Boys, is a South Korean boy band formed in 2010. The band consists of Jin, Suga, J-Hope, RM, Jimin, \n",
            "\n",
            "==== 2024 Nobel Prize in Literature ====\n",
            "The 2024 Nobel Prize in Literature was awarded to the South Korean author Han Kang (born 1970) \"for her intense poetic prose that confronts historical traumas and exposes the fragility of human life\".\n",
            "\n",
            "==== Han Kang ====\n",
            "Han Kang (Korean: ÌïúÍ∞ï; born 27 November 1970) is a South Korean writer. From 2007 to 2018, she taught creative writing at the Seoul Institute of the Arts. Han rose to international prominence for her n\n",
            "\n",
            "==== Bong Joon Ho ====\n",
            "Bong Joon Ho (Korean: Î¥âÏ§ÄÌò∏; pronounced [poÀê≈ã t…ïuÀênho]; born September 14, 1969) is a South Korean filmmaker. His work is characterized by emphasis on social and class themes, genre-mixing, dark comedy,\n",
            "\n",
            "==== Pachinko ====\n",
            "Pachinko (Japanese: „Éë„ÉÅ„É≥„Ç≥; pronounced [pat…ïi≈ãko]) is a mechanical game originating in Japan that is used as an arcade game and, much more frequently, for gambling. Pachinko fills a niche in Japanese ga\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Script A ‚Äî create one TXT file per title\n",
        "\n",
        "- All scripts use Wikipedia API"
      ],
      "metadata": {
        "id": "rp5gGha1olqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"wiki_txts\", exist_ok=True)\n",
        "\n",
        "for title in titles:\n",
        "    txt = get_wikipedia_page(title)\n",
        "    if not txt:\n",
        "        print(f\"Skipping: {title}\")\n",
        "        continue\n",
        "\n",
        "    fname = title.replace(\" \", \"_\").replace(\"'\", \"\") + \".txt\"\n",
        "    path = os.path.join(\"wiki_txts\", fname)\n",
        "\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(txt)\n",
        "\n",
        "    print(f\"Saved: {path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPACUy0NomoC",
        "outputId": "80a1a1a9-716b-4bb3-aa0b-c1df0ceee96b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: wiki_txts/K-pop.txt\n",
            "Saved: wiki_txts/Korean_Wave.txt\n",
            "Saved: wiki_txts/KPop_Demon_Hunters.txt\n",
            "Saved: wiki_txts/Hybe.txt\n",
            "Saved: wiki_txts/BTS.txt\n",
            "Saved: wiki_txts/2024_Nobel_Prize_in_Literature.txt\n",
            "Saved: wiki_txts/Han_Kang.txt\n",
            "Saved: wiki_txts/Bong_Joon_Ho.txt\n",
            "Saved: wiki_txts/Pachinko.txt\n",
            "Skipping: Minjung Son\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Script B ‚Äî Create one TXT file with records separated by @"
      ],
      "metadata": {
        "id": "DbDJlihQpwyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = []\n",
        "\n",
        "for title in titles:\n",
        "    txt = get_wikipedia_page(title)\n",
        "    if not txt:\n",
        "        txt = \"\"   # store empty if missing\n",
        "    block = f\"@@@@@\\nTITLE: {title}\\n{txt}\\n\"\n",
        "    output.append(block)\n",
        "\n",
        "final = \"\\n\".join(output)\n",
        "\n",
        "with open(\"wiki_corpus_delimited.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final)\n",
        "\n",
        "print(\"Saved: wiki_corpus_delimited.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQahv4M_p04U",
        "outputId": "5b74d3db-9f4c-4c8a-b020-d3491b0c8370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: wiki_corpus_delimited.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Script C ‚Äî Create one CSV with two columns (title + text)\n",
        "\n",
        "#üêπ üêæ üìå **Use this!!!**üìå"
      ],
      "metadata": {
        "id": "DsfmSdsvpSMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv #ÏπºÎüºÏÑ∏ÌçºÎ†àÏù¥Ìä∏Î≤®Î•ò\n",
        "\n",
        "rows = []\n",
        "\n",
        "for title in titles:\n",
        "    txt = get_wikipedia_page(title)\n",
        "    rows.append([title, txt])\n",
        "\n",
        "with open(\"wiki_corpus.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"title\", \"text\"])\n",
        "    writer.writerows(rows)\n",
        "\n",
        "print(\"Saved: wiki_corpus.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz9fgA47pT7x",
        "outputId": "343d8ec5-4c2c-4f48-d965-656933d47b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: wiki_corpus.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'>üêπ üêæ **Gutenberg project [by downloading]**"
      ],
      "metadata": {
        "id": "LAeTOcX1wNpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìï **Children's Picture Books**\n",
        "###[**Project Gutenberg**](https://gutenberg.org/)\n",
        "- **Beatrix Potter: Search by 'Beatrix Potter'**\n",
        "    - **The Tale of Peter Rabit**\n",
        "    - **The Tale of Benjamin Bunny**\n",
        "    - **The Tale of Jemima Puddle-Duck**\n",
        "    - **The Tale of Mrs. Tiggy-Winkle**\n",
        "    - **The Tale of Squirrel Nutkin**\n",
        "    - **The Tale of Tom Kitten**\n",
        "\n",
        "- **Leslie Brooke: Search by 'Leslie Brooke'**\n",
        "    - **The Tailor and the Crow**\n",
        "    - **The Golden Goose Book**\n",
        "    - **Jonny Crow's Garden**\n",
        "    - **A Nursery Rhyme Picture Book**"
      ],
      "metadata": {
        "id": "ai_fUazdwuyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 1**\n",
        "\n",
        "- **For each volume, take a look at a published version with the tab, \"READ NOW.\"**\n",
        "- **Download UTF-8 on your machine**\n",
        "- **Open your Î©îÎ™®Ïû• or TextEdit.**\n",
        "- **Save it as plain text.**"
      ],
      "metadata": {
        "id": "Nx5GplLzw1t7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2**\n",
        "- Make a folder on your Github repository with a new name \"Data_Plain\"\n",
        "- Upload"
      ],
      "metadata": {
        "id": "Ci4EcAxFw6Qh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'red'> üêπüêæ **Final Script to prepare input text for further analysis (e.g., Common Core Words, Wordcloud, Lexical Diversity, etc.)**\n",
        "\n",
        "  - # <font color = 'blue'> üêπüêæ **Important & Useful!**\n",
        "  - ### **This script will be based on plain text for 10 volumes above.**"
      ],
      "metadata": {
        "id": "WKoG5Nt6xINA"
      }
    }
  ]
}